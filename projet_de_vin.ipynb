{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPtSLTNZPhZiVLFLCkK1J2J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Billy-24/Billy-24/blob/main/projet_de_vin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohx50EumRhpD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, pathlib, PIL, shutil, glob\n",
        "from google.colab import files\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from pandas.core.dtypes.api import is_numeric_dtype, is_string_dtype\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder, FunctionTransformer, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import boxcox\n",
        "from scipy.stats import pearsonr\n",
        "import graphviz\n",
        "from yellowbrick.features import pca_decomposition\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "uploaded = files.upload()\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.stats import zscore"
      ],
      "metadata": {
        "id": "etY9dKtfcBpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# L'analyse exploratoire des données\n",
        "data = pd.read_csv(io.BytesIO(uploaded['winemag-data-130k-v2 (3).csv']))\n",
        "data.head()"
      ],
      "metadata": {
        "id": "p3lB6-9jhR9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "C099vIgNEPFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type de variable du dataset\n",
        "data.info()"
      ],
      "metadata": {
        "id": "X6qBzg8lbk8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.region_1.nunique()"
      ],
      "metadata": {
        "id": "2uyAOKfSvz_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "GisR8MWyETZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer les colonnes non pertinentes\n",
        "data = data.drop(['Unnamed: 0','region_2', 'description', 'taster_twitter_handle'], axis=1)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "K9vNPysCGx1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe(include=\"all\")"
      ],
      "metadata": {
        "id": "ZKnLhSeIEe1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vérification des valeurs manquantes dans le dataset\n",
        "plt.figure(figsize=(20,10))\n",
        "sns.heatmap(data.isna(), cbar=False)"
      ],
      "metadata": {
        "id": "27IKB7YNffjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verification des doublons\n",
        "duplicatas = data[data.duplicated()]\n",
        "print(\"Enregistrements Dupliqués :\", duplicatas.shape)"
      ],
      "metadata": {
        "id": "GIZqUX3Mh6Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#supprimons les doublons\n",
        "data.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "PQg1Mpx5jBrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "IJ0lE0wLj_Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# L'ensemble de données présente toutes les variables prédictives comme catégoriques, à l'exception du « prix ». La variable dépendante est « points ».cat_data=[]\n",
        "# Sectionner les catégories des valeur numériques\n",
        "cat_data=[]\n",
        "num_data=[]\n",
        "for i,c in enumerate(data.dtypes):\n",
        "  if c==object:\n",
        "    cat_data.append(data.iloc[:,i])\n",
        "  else:\n",
        "    num_data.append(data.iloc[:,i])\n",
        "cat_data=pd.DataFrame(cat_data)\n",
        "cat_data"
      ],
      "metadata": {
        "id": "v7azw8AvFpJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transposer les valeurs manquantes sectionnées\n",
        "cat_data=[]\n",
        "num_data=[]\n",
        "for i,c in enumerate(data.dtypes):\n",
        "  if c==object:\n",
        "    cat_data.append(data.iloc[:,i])\n",
        "  else:\n",
        "    num_data.append(data.iloc[:,i])\n",
        "cat_data=pd.DataFrame(cat_data).transpose()\n",
        "num_data=pd.DataFrame(num_data).transpose()\n",
        "cat_data"
      ],
      "metadata": {
        "id": "mhXt2HftJz2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "sns.heatmap(num_data.isna(), cbar=False)"
      ],
      "metadata": {
        "id": "atKQWLq_-Nt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse univariée des valeur catégoriele\n",
        "cat_data = ['country', 'taster_name']\n",
        "\n",
        "# Créer une grille de sous-graphiques en fonction du nombre de catégories\n",
        "fig, axes = plt.subplots(nrows=1, ncols=len(cat_data), figsize=(12, 4))\n",
        "\n",
        "# Parcourir la liste des catégories et créer un countplot pour chaque catégorie\n",
        "for i, column in enumerate(cat_data):\n",
        "    sns.countplot(x=column, data=data, ax=axes[i])\n",
        "    axes[i].set_xticklabels([])\n",
        "    axes[i].set_title(f'Countplot for {column}')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tDZMdyjcI304"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse des valeurs numériques\n",
        "data[['points','price']].describe()"
      ],
      "metadata": {
        "id": "nBiF4LpcMRKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyser la correlation entre price et points\n",
        "data[['price','points']].corr(method = 'pearson')"
      ],
      "metadata": {
        "id": "SfcvYzmrJ2YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carte de corrélation\n",
        "plt.figure(figsize=(2,2),)\n",
        "correlacion = data.corr()\n",
        "sns.heatmap(correlacion,annot=True)"
      ],
      "metadata": {
        "id": "kISSatgJOYgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suite à ce résultat 'il existe une corrélation positive modérée entre 'price' et 'points' dans vos données. Cela suggère qu'il y a une tendance générale selon laquelle des vins avec des prix plus élevés ont tendance à obtenir des points plus élevés, et vice versa. Cependant, d'autres facteurs peuvent également influencer la notation des vins, car la corrélation n'est pas parfaite."
      ],
      "metadata": {
        "id": "d9VkEQMsLkyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse country - points\n",
        "data[['points','country']].describe()"
      ],
      "metadata": {
        "id": "z4kq24PMMm3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_countries = data.groupby(['country'])['points'].mean().sort_values(ascending=False).head(10)\n",
        "print(top_countries)"
      ],
      "metadata": {
        "id": "YlmaItrBNN1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse des variables numériques\n",
        "# Analyse univariée des valeurs numériques : Créez un nuage de points avec 'price' sur l'axe des x\n",
        "plt.scatter(range(len(data['price'])), data['price'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4_YeIdDxLMnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 1 : Supprimer la valeur aberrante dans 'price'\n",
        "seuil_aberrant = 3200\n",
        "num_data = num_data[num_data['price'] <= seuil_aberrant]"
      ],
      "metadata": {
        "id": "RHRwHqCiiRXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nuage de points après suppression de la valeur aberrante\n",
        "plt.scatter(range(len(num_data['price'])), num_data['price'])\n",
        "plt.title('Nuage de points après suppression de la valeur aberrante')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VpSupqdloEh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remplaçons les valeur manquante numérique par le mean\n",
        "num_data.fillna(method = 'bfill' , inplace= True)\n",
        "num_data.isnull().sum().any()"
      ],
      "metadata": {
        "id": "BaXShLS6AcDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 4 : Remplacer les valeurs manquantes dans le reste de 'cat_data' par le mode\n",
        "cat_data.fillna(cat_data.mode().iloc[0], inplace=True)"
      ],
      "metadata": {
        "id": "6iJ5700q_xEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher les valeurs manquantes après le remplacement par la moyenne dans 'price'\n",
        "print(\"Valeurs manquantes dans 'price' après remplacement par la moyenne:\")\n",
        "print(num_data['price'].isnull().sum())\n",
        "\n",
        "# Afficher les valeurs manquantes dans le reste de 'num_data'\n",
        "print(\"Valeurs manquantes dans le reste de 'num_data' après remplacement par la moyenne:\")\n",
        "print(num_data.isnull().sum())\n"
      ],
      "metadata": {
        "id": "uRTpWl6rqiHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Un test pour voir si on retrouve encore des NAN dans le dataset\n",
        "plt.figure(figsize=(20,10))\n",
        "sns.heatmap(num_data.isna(), cbar=False)"
      ],
      "metadata": {
        "id": "QgkCkCQG9hfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse\n",
        "## le « prix » présente une grande quantité de données atypiques et une large marge. Avec la transformation logarithmique, un comportement plus normalisé est obtenu et la limite des données aberrantes est réduite. Cependant, la transformation boxcox, qui est plus généralisée et a des valeurs nulles et négatives, présente une normalisation légère mais meilleure que la transformation logarithmique.\n",
        "##La variable créée 'quality_price_ratio' présente un comportement qui tend à se normaliser, pour améliorer cette normalisation, une transformation sera effectuée. #"
      ],
      "metadata": {
        "id": "tFmWzTcbUZ_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data['quality_price_ratio'] = data['points'] / data['price']#"
      ],
      "metadata": {
        "id": "aQ8v-84RXNRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Réinitialiser les index des DataFrames\n",
        "num_data.reset_index(drop=True, inplace=True)\n",
        "cat_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Fusionner (concaténer) les deux DataFrames\n",
        "data_final = pd.concat([num_data, cat_data], axis=1)\n",
        "data_final"
      ],
      "metadata": {
        "id": "E3x31xmeBtcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fusionner dataset à cette étape (combined_data)\n",
        "combined_data = pd.concat([cat_data, num_data], axis=1)\n",
        "\n",
        "combined_data"
      ],
      "metadata": {
        "id": "76KU8d1UrwPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_data"
      ],
      "metadata": {
        "id": "C_t7oIBQAAy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Un test pour voir si on retrouve encore des NAN dans le dataset\n",
        "plt.figure(figsize=(20,10))\n",
        "sns.heatmap(data_final.isna(), cbar=False)"
      ],
      "metadata": {
        "id": "hAEGA1Mym0V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data = pd.DataFrame(data)\n",
        "\n",
        "# Encoder les variables catégorielles avec l'encodage one-hot\n",
        "combined_data_encoded = pd.get_dummies(combined_data, columns=['country', 'designation', 'province', 'region_1', 'taster_name', 'variety', 'winery'])\n",
        "\n",
        "# Afficher le DataFrame encodé\n",
        "print(combined_data_encoded)"
      ],
      "metadata": {
        "id": "oKLKpvEpZft2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Training pipeline ###\n",
        "print(\"--- Training pipeline ---\")\n",
        "print()\n",
        "\n",
        "# Encoding categorical features and standardizing numeric features\n",
        "\n",
        "print(\"#### X_train BEFORE preprocessing ####\")\n",
        "print(combined_data.head())\n",
        "print()\n",
        "\n",
        "print(\"Encoding categorical features and standardizing numerical features...\")\n",
        "## First let's import libraries\n",
        "## StandardScaler to scale data (i.e apply Z-score)\n",
        "## OneHotEncoder to encode categorical variables\n",
        "\n",
        "\n",
        "numeric_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History'] # Choose which column index we are going to scale\n",
        "numeric_transformer = StandardScaler()\n",
        "\n",
        "categorical_features = ['Gender', 'Married', 'Dependents', 'Education','Self_Employed','Property_Area'] # Choose which column index we are going to encode\n",
        "categorical_transformer = OneHotEncoder(drop=\"first\")\n",
        "\n",
        "# Apply ColumnTransformer to create a pipeline that will apply the above preprocessing\n",
        "feature_encoder = ColumnTransformer(transformers=[('cat', categorical_transformer, categorical_features), ('num', numeric_transformer, numeric_features)])\n",
        "# Apply ColumnTransformer to create a pipeline that will apply the above preprocessing\n",
        "feature_encoder = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', categorical_transformer, categorical_features),\n",
        "        ('num', numeric_transformer, numeric_features)\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "elWmnbHMS7ys"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}